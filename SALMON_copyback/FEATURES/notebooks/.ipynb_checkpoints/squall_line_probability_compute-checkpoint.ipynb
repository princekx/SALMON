{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070c8039-0310-450a-8a3a-fafef18e5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import multiprocessing\n",
    "import concurrent\n",
    "import subprocess\n",
    "import uuid\n",
    "from iris.fileformats.pp import load_pairs_from_fields\n",
    "import numpy as np\n",
    "import logging\n",
    "import warnings\n",
    "import os, sys\n",
    "import scipy.ndimage as ndimage\n",
    "from skimage import measure\n",
    "#from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d143fd5-47b5-4c2e-a730-480e81b4d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_features(cube, thresholds=None, time_index=0, member=0, threshold_method='geq'):\n",
    "    '''\n",
    "    2D cube tracking for thresholds\n",
    "    :param cube: Lat-lon cube\n",
    "    :type cube:\n",
    "    :param thresholds:\n",
    "    :type thresholds:\n",
    "    :param time_index:\n",
    "    :type time_index:\n",
    "    :param threshold_method:\n",
    "    :type threshold_method:\n",
    "    :return: DataFrame of identified objects and their properties\n",
    "    :rtype: Pandas DataFrame\n",
    "    '''\n",
    "    assert thresholds is not None, \"Threshold values not found.\"\n",
    "\n",
    "    # indices = []\n",
    "    time_indices = []\n",
    "    mem_indices = []\n",
    "    cube_dates = []\n",
    "    object_coords = []\n",
    "    object_labels = []\n",
    "    threshold_values = []\n",
    "    areas = []\n",
    "    perimeters = []\n",
    "    eccs = []\n",
    "    orients = []\n",
    "    centroids = []\n",
    "    mean_values = []\n",
    "    std_values = []\n",
    "    max_values = []\n",
    "    min_values = []\n",
    "    ngrid_points = []\n",
    "    forecast_period = []\n",
    "    forecast_reference_time = []\n",
    "    data_values = []\n",
    "    surface_type = []\n",
    "    index = time_index\n",
    "    if cube.ndim == 2:\n",
    "        ny, nx = cube.shape\n",
    "        lons, lats = cube.coord('longitude').points, cube.coord('latitude').points\n",
    "\n",
    "        # Cube date\n",
    "        if cube.coords('time'):\n",
    "            c_date = cube.coord('time').units.num2date(cube.coord('time').points)[0]\n",
    "            cube_date = datetime.datetime(c_date.year, c_date.month, c_date.day)\n",
    "\n",
    "        if cube.coords('forecast_reference_time'):\n",
    "            frt = cube.coord('forecast_reference_time').units.num2date(\n",
    "                cube.coord('forecast_reference_time').points)[0]\n",
    "            forecast_rt = datetime.datetime(frt.year, frt.month, frt.day)\n",
    "        else:\n",
    "            forecast_rt = np.nan\n",
    "\n",
    "        if cube.coords('forecast_period'):\n",
    "            forecast_p = cube.coord('forecast_period').points[0]\n",
    "        else:\n",
    "            forecast_p = np.nan\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            # print('Thresholding %s' %threshold)\n",
    "            cube_data = cube.data.copy()\n",
    "            mask = generate_mask(cube_data, threshold, threshold_method)\n",
    "\n",
    "            # Label each feature in the mask\n",
    "            labeled_array, num_features = ndimage.measurements.label(mask)\n",
    "            # print('%s features labelled.' % num_features)\n",
    "            # labelled_array is a mask hence != operator below\n",
    "            for feature_num in range(1, num_features):\n",
    "                print_progress_bar(feature_num + 1, num_features)\n",
    "\n",
    "                # threshold\n",
    "                threshold_values.append(threshold)\n",
    "                object_labels.append(f'{index}_{member}_{threshold}_{feature_num}')\n",
    "                loc = labeled_array != feature_num\n",
    "                data_object = np.ma.masked_array(cube_data, loc)\n",
    "\n",
    "                ###### Skimage needs the mask reversed\n",
    "                lab_image = measure.label(labeled_array == feature_num)\n",
    "                region = measure.regionprops(lab_image, np.ma.masked_array(cube_data, ~loc))\n",
    "\n",
    "                # perimeter, eccentricity, orientation\n",
    "                areas.append([p.area for p in region][0])\n",
    "                perimeters.append([p.perimeter for p in region][0])\n",
    "                eccs.append([p.eccentricity for p in region][0])\n",
    "                orients.append([p.orientation for p in region][0])\n",
    "                # print(eccs)\n",
    "                ###############\n",
    "\n",
    "                data_values.append(data_object.compressed())\n",
    "                mean_values.append(np.ma.mean(data_object))\n",
    "                std_values.append(np.ma.std(data_object))\n",
    "                max_values.append(np.ma.max(data_object))\n",
    "                min_values.append(np.ma.min(data_object))\n",
    "\n",
    "                try:\n",
    "                    y, x = ndimage.measurements.center_of_mass(data_object)\n",
    "                    centroids.append((lons[round(x)], lats[round(y)]))\n",
    "                except:\n",
    "                    centroids.append((np.nan, np.nan))\n",
    "\n",
    "                object_inds = np.where(loc == False)\n",
    "                object_lats = [lats[i] for i in object_inds[0]]\n",
    "                object_lons = [lons[i] for i in object_inds[1]]\n",
    "\n",
    "                object_coords.append([(x, y) for x, y in zip(object_lons, object_lats)])\n",
    "\n",
    "                # surface type\n",
    "                # This slows the computation down significantly\n",
    "                # surface_type.append(check_land_or_ocean(object_lons, object_lats))\n",
    "\n",
    "                ngrid_points.append(len(object_lats))\n",
    "\n",
    "                cube_dates.append(cube_date)\n",
    "                forecast_period.append(forecast_p)\n",
    "                forecast_reference_time.append(forecast_rt)\n",
    "                # indices.append(index)\n",
    "                time_indices.append(index)\n",
    "                mem_indices.append(member)\n",
    "\n",
    "        index += 1\n",
    "    features = {'TimeInds': time_indices, 'Date': cube_dates,\n",
    "                'Forecast_period': forecast_period, 'Forecast_reference_time': forecast_reference_time,\n",
    "                'Threshold': threshold_values, 'ObjectLabel': object_labels, 'Area': areas,\n",
    "                'GridPoints': ngrid_points,\n",
    "                'Mean': mean_values, 'Std': std_values,\n",
    "                'Max': max_values, 'Min': min_values,\n",
    "                'Centroid': centroids, 'Polygon': object_coords, 'Data_values': data_values,\n",
    "                'Perimeter': perimeters, 'Eccentricity': eccs, 'Orientation': orients}\n",
    "\n",
    "    features = pd.DataFrame(features, columns=['TimeInds', 'Date', 'Forecast_period',\n",
    "                                               'Forecast_reference_time', 'Threshold', 'ObjectLabel', 'Area',\n",
    "                                               'Perimeter',\n",
    "                                               'GridPoints', 'Eccentricity', 'Orientation',\n",
    "                                               'Mean', 'Std', 'Max', 'Min', 'Centroid', 'Polygon', 'Data_values'])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44adca22-f124-45e8-bcaf-5192d1619f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/scitools/conda/deployments/default-2024_05_28/lib/python3.11/site-packages/iris/__init__.py:354: FutureWarning: Ignoring a datum in netCDF load for consistency with existing behaviour. In a future version of Iris, this datum will be applied. To apply the datum when loading, use the iris.FUTURE.datum_support flag.\n",
      "  cubes = _load_collection(uris, constraints, callback).cubes()\n"
     ]
    }
   ],
   "source": [
    "cubes = iris.load_cube('/scratch/hadpx/SEA_monitoring/processed_SEA_data/mogreps/features/precip/precip_Features_24h_allMember_20241001.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3e8d82-dea7-4d18-8f72-35d68f432cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 8\n"
     ]
    }
   ],
   "source": [
    "nmembers, ntime, _, _ = cubes.shape\n",
    "print(nmembers, ntime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cfc56e5-705a-498e-9e5f-f97ec5ad02c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DimCoord: realization / (unknown)  [ 0, 1, ..., 34, 35]  shape(36,)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "for i in range(ntime):\n",
    "    for mem in range(nmembers):\n",
    "        frames.append(grid_features(cubes[mem, i], thresholds=thresholds, time_index=i,\n",
    "                                            threshold_method=threshold_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5ed7d-aed1-49fc-a710-d1f321fd648f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
